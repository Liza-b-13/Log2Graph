import streamlit as st
import src.extract_events as extractor
import src.build_graph as builder
import src.detect as detector
import src.visualize as viz
import src.utils as utils
import networkx as nx
import tempfile, os, json
from time import sleep

st.set_page_config(page_title="LateralSight Demo", layout="wide")

# --- HEADER ---
st.title("ğŸ§  LateralSight â€” Prototype LLM-assisted Knowledge Graph")
st.markdown("""
Pipeline interactif : **logs â†’ Ã©vÃ©nements â†’ graphe â†’ dÃ©tection**

ğŸ’¡ **Conseil** : chargez un CSV ou utilisez le fichier d'exemple, puis cliquez sur "ğŸš€ Lancer le pipeline".
""")

st.divider()

# --- USER INPUT ZONE ---
st.subheader("âš™ï¸ Configuration du test")
col1, col2 = st.columns([1,2])
with col1:
    mode = st.radio("Mode d'extraction :", ["rule", "llm"], horizontal=True)
with col2:
    uploaded = st.file_uploader("Importer un fichier CSV (ou utiliser l'exemple fourni)", type=["csv"])

use_sample = False
if uploaded is None:
    st.info("Aucun fichier chargÃ© â€” le fichier `sample_logs.csv` sera utilisÃ©.")
    use_sample = True

run = st.button("ğŸš€ Lancer le pipeline")

if run:
    # --- Ã‰tape 0 : initialisation ---
    progress = st.progress(0)
    status_box = st.empty()

    # Ã‰tape 1 : charger le fichier CSV
    status_box.info("ğŸ“„ Ã‰tape 1 â€” Extraction des Ã©vÃ©nements...")
    sleep(0.3)
    if use_sample:
        csv_path = "sample_logs.csv"
    else:
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".csv")
        tmp.write(uploaded.getvalue())
        tmp.flush()
        csv_path = tmp.name

    events = extractor.parse_csv_to_events(csv_path, mode=mode)
    progress.progress(20)
    status_box.success(f"âœ… {len(events)} Ã©vÃ©nements extraits")
    st.json(events[:5])

    # Ã‰tape 2 : construire le graphe
    status_box.info("ğŸ•¸ï¸ Ã‰tape 2 â€” Construction du graphe...")
    sleep(0.3)
    G = builder.build_graph_from_events(events)
    builder.save_graph_gml(G, "tmp_graph.gml")
    progress.progress(50)
    st.success(f"Graphe construit : **{len(G.nodes())} nÅ“uds**, **{len(G.edges())} arÃªtes**")

    # Ã‰tape 3 : dÃ©tection
    status_box.info("ğŸš¨ Ã‰tape 3 â€” DÃ©tection dâ€™anomalies...")
    sleep(0.3)
    kb = utils.read_json("data/kb_patterns.json")
    alerts = detector.detect_patterns_in_graph(G, kb)
    progress.progress(75)

    if alerts:
        st.error(f"{len(alerts)} alerte(s) dÃ©tectÃ©e(s) â—")
        for a in alerts:
            st.markdown(f"**Pattern:** {a['pattern_name']}\n**Chemin:** {a['path']}\n**Actions:** {a['actions_sequence']}")
    else:
        st.success("âœ… Aucune alerte dÃ©tectÃ©e")

    # Ã‰tape 4 : visualisation
    status_box.info("ğŸ” Ã‰tape 4 â€” Visualisation du graphe...")
    sleep(0.3)
    fig = viz.draw_graph(G, figsize=(10,7))
    st.pyplot(fig)
    progress.progress(100)
    status_box.success("ğŸ‰ Pipeline terminÃ© !")

    if not use_sample:
        os.unlink(csv_path)

# --- SIDEBAR ---
st.sidebar.header("â„¹ï¸ Aide & infos")
st.sidebar.markdown("""
**LateralSight** permet de :
- Extraire des Ã©vÃ©nements Ã  partir de logs
- Construire un graphe de relations
- DÃ©tecter des patterns suspects
- Visualiser les interactions

ğŸ’» DÃ©veloppÃ© pour illustrer un pipeline *LLM-assisted Knowledge Graph*.
""")
